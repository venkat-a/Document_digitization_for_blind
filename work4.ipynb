{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f47fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (10.2.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.5.3)\n",
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, gast, astunparse, absl-py, tensorboard, scikit-learn, markdown-it-py, rich, keras, tensorflow, scikeras\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.4.1.post1\n",
      "    Uninstalling scikit-learn-1.4.1.post1:\n",
      "      Successfully uninstalled scikit-learn-1.4.1.post1\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 grpcio-1.64.1 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 rich-13.7.1 scikeras-0.13.0 scikit-learn-1.5.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy matplotlib scikit-learn pillow pandas scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76089be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83c0532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 18:47:49.425239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 18:47:50.663017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494f5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723b723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d31f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4647066",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ef46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8dfb093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2393 images belonging to 3 classes.\n",
      "Found 597 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation data should not be augmented, only rescaled\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'images/training',  # Path to your training data\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'images/testing',  # Path to your validation data\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9c8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92998e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model(input_shape=(224, 224, 3), num_classes=3, learning_rate=0.001, l2_reg=0.001, activation='relu', optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation=activation, input_shape=input_shape, kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=activation, kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation=activation, kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(256, (3, 3), activation=activation, kernel_regularizer=l2(l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation=activation, kernel_regularizer=l2(l2_reg)),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation=activation, kernel_regularizer=l2(l2_reg)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        opt = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223687d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d89ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_baseline_model, input_shape=(224, 224, 3), num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235566e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4a55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, min_delta=0.05, mode='max', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c698f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d5b7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'model__learning_rate': [0.0001, 0.01],\n",
    "    'model__l2_reg': [0.0001, 0.01],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__optimizer': ['adam', 'sgd'],\n",
    "    'fit__epochs': [1],\n",
    "    'fit__batch_size': [32]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d16c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a5733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=adam; total time=  49.3s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=adam; total time=  46.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=adam; total time=  46.2s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=sgd; total time=  46.3s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=sgd; total time=  46.0s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=sgd; total time=  46.2s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=rmsprop; total time=  45.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=rmsprop; total time=  45.7s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=rmsprop; total time=  45.1s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=adagrad; total time=  45.2s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=adagrad; total time=  45.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.0001, model__optimizer=adagrad; total time=  45.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=adam; total time=  45.4s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=adam; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=adam; total time=  45.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=sgd; total time=  45.4s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=sgd; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=sgd; total time=  45.9s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=rmsprop; total time=  46.0s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=rmsprop; total time=  45.8s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=rmsprop; total time=  45.7s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=adagrad; total time=  45.7s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=adagrad; total time=  45.4s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.001, model__optimizer=adagrad; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=adam; total time=  45.7s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=adam; total time=  46.9s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=adam; total time=  46.7s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=sgd; total time=  46.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=sgd; total time=  46.9s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=sgd; total time=  46.8s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=rmsprop; total time=  46.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=rmsprop; total time=  46.4s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=rmsprop; total time=  46.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=adagrad; total time=  47.0s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=adagrad; total time=  46.8s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.0001, model__learning_rate=0.01, model__optimizer=adagrad; total time=  47.1s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=adam; total time=  46.2s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=adam; total time=  46.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=adam; total time=  46.1s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=sgd; total time=  46.4s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=sgd; total time=  46.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=sgd; total time=  45.8s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=rmsprop; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=rmsprop; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=rmsprop; total time=  45.8s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=adagrad; total time=  45.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=adagrad; total time=  46.1s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.0001, model__optimizer=adagrad; total time=  46.4s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.001, model__optimizer=adam; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.001, model__optimizer=adam; total time=  45.9s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.001, model__optimizer=adam; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.001, model__optimizer=sgd; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.001, model__optimizer=sgd; total time=  45.6s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.001, model__optimizer=sgd; total time=  45.5s\n",
      "[CV] END fit__batch_size=32, fit__epochs=1, model__activation=relu, model__l2_reg=0.001, model__learning_rate=0.001, model__optimizer=rmsprop; total time=  45.6s\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=2, n_jobs=1)\n",
    "grid_search_result = grid_search.fit(train_generator, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4273494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d08ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best: {grid_search_result.best_score_} using {grid_search_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee3cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a70683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = create_baseline_model(\n",
    "    input_shape=(224, 224, 3),\n",
    "    num_classes=3,\n",
    "    learning_rate=best_params['model__learning_rate'],\n",
    "    l2_reg=best_params['model__l2_reg'],\n",
    "    activation=best_params['model__activation'],\n",
    "    optimizer=best_params['model__optimizer']\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=best_params['fit__epochs'],\n",
    "    batch_size=best_params['fit__batch_size'],\n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390bde73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet50_model(input_shape=(224, 224, 3), num_classes=3, learning_rate=0.001, activation='relu', optimizer='adam'):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation=activation)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    if optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        opt = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5edfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d932f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_resnet50_model, input_shape=(224, 224, 3), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51549244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'model__learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'model__activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'model__optimizer': ['adam', 'sgd', 'rmsprop', 'adagrad'],\n",
    "    'fit__epochs': [1],\n",
    "    'fit__batch_size': [32, 64]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20547fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=2, n_jobs=1)\n",
    "grid_search_result = grid_search.fit(train_generator, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd21839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best: {grid_search_result.best_score_} using {grid_search_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a935d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ebfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search_result.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eddd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f0c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = create_resnet50_model(\n",
    "    input_shape=(224, 224, 3),\n",
    "    num_classes=3,\n",
    "    learning_rate=best_params['model__learning_rate'],\n",
    "    activation=best_params['model__activation'],\n",
    "    optimizer=best_params['model__optimizer']\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=best_params['fit__epochs'],\n",
    "    batch_size=best_params['fit__batch_size'],\n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3072b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientnet_model(input_shape=(224, 224, 3), num_classes=3, learning_rate=0.001, activation='relu', optimizer='adam'):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation=activation)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    if optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        opt = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dada09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96159bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_efficientnet_model, input_shape=(224, 224, 3), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d46307",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'model__learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'model__activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'model__optimizer': ['adam', 'sgd', 'rmsprop', 'adagrad'],\n",
    "    'fit__epochs': [1],\n",
    "    'fit__batch_size': [32, 64]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161ac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f20c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=2, n_jobs=1)\n",
    "grid_search_result = grid_search.fit(train_generator, validation_data=test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9619128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best: {grid_search_result.best_score_} using {grid_search_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f7239f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbe308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = create_efficientnet_model(\n",
    "    input_shape=(224, 224, 3),\n",
    "    num_classes=3,\n",
    "    learning_rate=best_params['model__learning_rate'],\n",
    "    activation=best_params['model__activation'],\n",
    "    optimizer=best_params['model__optimizer']\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=best_params['fit__epochs'],\n",
    "    batch_size=best_params['fit__batch_size'],\n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3459a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_baseline = baseline_model.fit(\n",
    "    train_generator, \n",
    "    validation_data=test_generator, \n",
    "    epochs=30, \n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")\n",
    "history_resnet50 = resnet50_model.fit(\n",
    "    train_generator, \n",
    "    validation_data=test_generator, \n",
    "    epochs=30, \n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")\n",
    "history_efficientnet = efficientnet_model.fit(\n",
    "    train_generator, \n",
    "    validation_data=test_generator, \n",
    "    epochs=30, \n",
    "    callbacks=[reduce_lr, early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee784ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, test_generator):\n",
    "    X = np.concatenate([model.predict(test_generator) for model in models], axis=1)\n",
    "    y = test_generator.classes\n",
    "    \n",
    "    meta_model = LogisticRegression(max_iter=1000)\n",
    "    meta_model.fit(X, y)\n",
    "    \n",
    "    X_test = np.concatenate([model.predict(test_generator) for model in models], axis=1)\n",
    "    y_pred = meta_model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a761e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb252519",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [final_baseline_model, resnet50_model, efficientnet_model]\n",
    "ensemble_predictions = ensemble_predict(models, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8df0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46dbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels = test_generator.classes\n",
    "ensemble_accuracy = accuracy_score(correct_labels, ensemble_predictions)\n",
    "print(f'Ensemble Accuracy: {ensemble_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2dbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
